version: "3.2"
services:

  # Hadoop HDFS Master node
  hdfsmaster:
    build: 
      context: ../nbaTrends-hadoop/docker
    command: ["master"]
    hostname: hdfsmaster
    ports:
      - 50070:50070
    networks:
      - hadoop

  # Hadoop HDFS Worker node
  hadoopworker:
    build: 
      context: ../nbaTrends-hadoop/docker
    command: ["worker"]
    depends_on:
      - hdfsmaster
    networks:
      - hadoop

  # Spark Master Node
  sparkmaster:
    build:
      context: ../nbaTrends-jobs
      dockerfile: docker/Dockerfile-spark
    command: ['master']
    hostname: sparkmaster
    ports: 
      - 30000:8080
    networks:
      - hadoop

  # Spark Worker Node
  sparkworker:
    build:
      context: ../nbaTrends-jobs
      dockerfile: docker/Dockerfile-spark
    command: ['worker']
    depends_on: 
      - sparkmaster
    networks:
      - hadoop

  # PySpark Jobs 
  jobs:
    build:
      context: ../nbaTrends-jobs
      dockerfile: docker/Dockerfile-jobs
    depends_on:
      - sparkmaster
      - hdfsmaster
    networks:
      - hadoop
      

# Network Configs
networks:
  hadoop:
    external:
      name: hadoop